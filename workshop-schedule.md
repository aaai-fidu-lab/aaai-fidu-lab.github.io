---
title: Schedule
nav: true
---

# Workshop Structure (Tentative)

Total Duration: 8 Hours

| Time              | Session                                  | Description                                                                                     |
|:------------------|:-----------------------------------------|:------------------------------------------------------------------------------------------------|
| **09:00 - 09:30** | **Welcome and Introduction**             | • Opening remarks<br>• Overview of workshop structure and objectives                            |
| **09:30 - 11:00** | **Reflections on the Landscape**         | • Collaborative reflection on the existing landscape<br>• Talks, panels, and breakouts by modality (text, images, audio, video, and multimodal data)<br>• Topics:<br>&nbsp;&nbsp;- Underlying frameworks<br>&nbsp;&nbsp;- Contextualization challenges<br>&nbsp;&nbsp;- Defining robust evaluations<br>&nbsp;&nbsp;- Incentive structures |
| **11:00 - 11:15** | **Break**                                |                                                                                                  |
| **11:15 - 12:45** | **Talks + Provocations**                 | • Invited speakers on current technical evaluations for base models across all modalities<br>• Key social impact categories covered:<br>&nbsp;&nbsp;- Bias and stereotyping<br>&nbsp;&nbsp;- Cultural values<br>&nbsp;&nbsp;- Performance disparities<br>&nbsp;&nbsp;- Privacy<br>&nbsp;&nbsp;- Financial and environmental costs<br>&nbsp;&nbsp;- Data moderator labor<br>• Presentations of accepted provocations |
| **12:45 - 13:45** | **Lunch Break**                          |                                                                                                  |
| **13:45 - 15:45** | **Group Activity**                       | • Participants break into groups focusing on key social impact categories<br>• Activities include:<br>&nbsp;&nbsp;1. Choosing Evaluations: Determining how to select evaluations from a large repository<br>&nbsp;&nbsp;2. Reviewing Tools and Datasets: Assessing existing artifacts and identifying gaps<br>&nbsp;&nbsp;3. Examining construct reliability, validity, and ranking methodologies |
| **15:45 - 16:00** | **Break**                                |                                                                                                  |
| **16:00 - 17:45** | **What's Next? Documentation + Resources** | • Develop policy guidance highlighting impact categories, subcategories, and modalities requiring further investment<br>• Discussions on:<br>&nbsp;&nbsp;1. Documenting Methods: Creating a proposed framework for documenting evaluations<br>&nbsp;&nbsp;2. Developing Shareable Resources: Improving evaluation repository and conceptualizing improved resources<br>&nbsp;&nbsp;3. Underlying Frameworks: Examining foundational frameworks influencing evaluations<br>&nbsp;&nbsp;4. Contextualization Challenges: Identifying challenges in contextualizing evaluations across different contexts<br>&nbsp;&nbsp;5. Defining Robust Evaluations: Establishing criteria for robust and meaningful evaluations |
| **17:45 - 18:00** | **Closing Remarks**                      |                                                                                                  |

